{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e67f61",
   "metadata": {},
   "source": [
    "# SVM : 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7ef0e",
   "metadata": {},
   "source": [
    "# AND, OR, XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efc445",
   "metadata": {},
   "source": [
    "### 1. AND 연산 : 두 개의 값이 모두 참일 때 참이된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb910e",
   "metadata": {},
   "source": [
    "### 2. OR 연산 : 둘 중에 하나만 참이어도 참이된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6623ad",
   "metadata": {},
   "source": [
    "### 3. XOR 연산 : 두 개의 값이 다른 경우 참이된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eec68a",
   "metadata": {},
   "source": [
    "## XOR()\n",
    "\n",
    "| A | B | Result |\n",
    "|-|-|-|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# 데이터 전처리 : 학습용/테스트 데이터 분리\n",
    "\n",
    "# 분류작업 머신\n",
    "clf = svm.SVC()\n",
    "\n",
    "    # train_data, train_label\n",
    "clf.fit(학습데이터, 학습정답)\n",
    "\n",
    "    # test_data\n",
    "predict(테스트데이터)\n",
    "\n",
    "            # test_label, 예측값\n",
    "accuracy_score(테스트정답, 예측값<predict>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b14d5",
   "metadata": {},
   "source": [
    "## 실제코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d93d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과 :  [0 1]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "# AND 연산\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit([\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1]\n",
    "], \n",
    "    [0, 0, 0, 1]\n",
    ")\n",
    "\n",
    "predict = clf.predict([\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "print(\"예측결과 : \", predict)\n",
    "\n",
    "score = accuracy_score([[0],[1]], predict)\n",
    "\n",
    "print(\"정확도 : \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2bbe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과 :  [0 1]\n",
      "\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "train_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "train_label = [0, 0, 0, 1]\n",
    "\n",
    "test_data = [[1, 0], [1, 1]]\n",
    "test_label = [0, 1]\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "predict = clf.predict(test_data)\n",
    "print(\"예측결과 : \" , predict)\n",
    "\n",
    "score = accuracy_score(test_label, predict)\n",
    "print(\"정확도 : \" , score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5b078",
   "metadata": {},
   "source": [
    "# 사이킷런 내장 데이터 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7ad86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런을 설치하면 샘플용 데이터가 자동으로 설치된다.\n",
    "# from sklearn.datasets import 탭키를 누르면 샘플데이터를 확인할 수 있다.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0307dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 객체 생성\n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce5e1b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset에 있는 key 값을 확인 (열 이름)\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset에 있는 values 값을 확인 (데이터)\n",
    "dataset.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5891b36",
   "metadata": {},
   "source": [
    "### 내장된 데이터의 정답 확인 : target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24bf620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a71c4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48a2c7",
   "metadata": {},
   "source": [
    "- 상세 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e8497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58187542",
   "metadata": {},
   "source": [
    "- 최적의 결과를 위해 데이터를 무작위로 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동으로 작업하는 경우\n",
    "\n",
    "import random\n",
    "random.shuffle(데이터)\n",
    "\n",
    "# 자동으로 작업하는 경우\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_label, test_label = \n",
    "                        train_test_split(dataset['data'], dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46d9ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(dataset['data'],dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97ad892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n",
      "(112,)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d71b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과 :  [1 0 0 0 1 2 2 2 1 2 2 0 2 2 1 2 0 1 0 1 0 1 0 2 1 2 2 0 2 2 1 2 0 0 2 1 1\n",
      " 0]\n",
      "정확도 :  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "predict = clf.predict(test_data)\n",
    "print(\"예측결과 : \" , predict)\n",
    "\n",
    "score = accuracy_score(test_label, predict)\n",
    "print(\"정확도 : \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c422321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.91      0.91      0.91        11\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.95      0.95      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "report = metrics.classification_report(test_label, predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f32191",
   "metadata": {},
   "source": [
    "precision : 예측\n",
    "\n",
    "0은 100%로 예측을 했다. 그의 신뢰도(recall)도 100%\n",
    "1은 91프로로 예측을 했다. 그의 신뢰도도 91프로이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36dc37",
   "metadata": {},
   "source": [
    "# one-hot-incoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset_cancer = load_breast_cancer()\n",
    "dataset_boston = load_boston()\n",
    "\n",
    "\n",
    "'''\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "predict = clf.predict(test_data)\n",
    "print(\"예측결과 : \" , predict)\n",
    "\n",
    "score = accuracy_score(test_label, predict)\n",
    "print(\"정확도 : \" , score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a116bf",
   "metadata": {},
   "source": [
    "# 손글씨 데이터 분류 : MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de88373",
   "metadata": {},
   "source": [
    "# http://yann.lecun.com/exdb/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53822f0",
   "metadata": {},
   "source": [
    "- train-images-idx3-ubyte     --- 학습용\n",
    "- train-labels-idx1-ubyte.gz  ---  정답\n",
    "- t10k-images-idx3-ubyte.gz   --- 테스트\n",
    "- t10k-labels-idx1-ubyte.gz   --- 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9afadce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download :  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "download :  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "download :  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "download :  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "gzip train-images-idx3-ubyte.gz\n",
      "gzip train-labels-idx1-ubyte.gz\n",
      "gzip t10k-images-idx3-ubyte.gz\n",
      "gzip t10k-labels-idx1-ubyte.gz\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "import gzip, os, os.path\n",
    "\n",
    "savepath = './mnist'\n",
    "baseurl = 'http://yann.lecun.com/exdb/mnist'\n",
    "files = [\n",
    "    \"train-images-idx3-ubyte.gz\",\n",
    "    \"train-labels-idx1-ubyte.gz\",\n",
    "    \"t10k-images-idx3-ubyte.gz\",\n",
    "    \"t10k-labels-idx1-ubyte.gz\"\n",
    "]\n",
    "\n",
    "# 파일 다운로드\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "    \n",
    "for f in files:\n",
    "    url = baseurl + '/' + f\n",
    "    loc = savepath + '/' + f\n",
    "    print(\"download : \", url)\n",
    "    \n",
    "    if not os.path.exists(loc):\n",
    "        req.urlretrieve(url, loc)\n",
    "        \n",
    "        \n",
    "# 압축해제\n",
    "for f in files:\n",
    "    gz_file = savepath + '/' + f\n",
    "    raw_file = savepath + '/' + f.replace('.gz', '')\n",
    "    print('gzip : ', f)\n",
    "    \n",
    "    with gzip.open(gz_file, 'rb') as fp:\n",
    "        body = fp.read()\n",
    "        \n",
    "        with open(raw_file, 'wb') as wp:\n",
    "            wp.write(body)\n",
    "            \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6943c5",
   "metadata": {},
   "source": [
    "# 이미지를 CSV 파일로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def to_csv(name, maxdata) :\n",
    "    lbl_f = open('./mnist/' + name + '-labels-idx1-ubyte', 'rb')\n",
    "    img_f = open('./mnist/' + name + '-images-idx3-ubyte', 'rb')\n",
    "    csv_f = open('./mnist/' + name + '.csv', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "346263dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "def to_csv(name, maxdata):\n",
    "    # 레이블 파일과 이미지 파일 열기\n",
    "    lbl_f = open(\"./mnist/\"+name+\"-labels-idx1-ubyte\", \"rb\")\n",
    "    img_f = open(\"./mnist/\"+name+\"-images-idx3-ubyte\", \"rb\")\n",
    "    csv_f = open(\"./mnist/\"+name+\".csv\", \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    # 헤더 정보 읽기 --- (※1)\n",
    "    # unpack : 데이터를 풀겠다.\n",
    "    # >II : 부호없는 정수형을 가져오겠다.\n",
    "    mag, lbl_count = struct.unpack(\">II\", lbl_f.read(8))\n",
    "    mag, img_count = struct.unpack(\">II\", img_f.read(8))\n",
    "    rows, cols = struct.unpack(\">II\", img_f.read(8))\n",
    "    pixels = rows * cols\n",
    "    # 28 * 28\n",
    "    \n",
    "    # 이미지 데이터를 읽고 CSV로 저장하기 --- (※2)\n",
    "    res = []\n",
    "    for idx in range(lbl_count):\n",
    "        if idx > maxdata: break\n",
    "        label = struct.unpack(\"B\", lbl_f.read(1))[0]\n",
    "        bdata = img_f.read(pixels)\n",
    "        sdata = list(map(lambda n: str(n), bdata))\n",
    "        csv_f.write(str(label)+\",\")\n",
    "        csv_f.write(\",\".join(sdata)+\"\\r\\n\")\n",
    "        \n",
    "        # 잘 저장됐는지 이미지 파일로 저장해서 테스트하기 -- (※3)\n",
    "        if idx < 10:\n",
    "            s = \"P2 28 28 255\\n\"\n",
    "            s += \" \".join(sdata)\n",
    "            iname = \"./mnist/{0}-{1}-{2}.pgm\".format(name,idx,label)\n",
    "            with open(iname, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(s)\n",
    "    csv_f.close()\n",
    "    lbl_f.close()\n",
    "    img_f.close()\n",
    "    \n",
    "# 결과를 파일로 출력하기 --- (※4)\n",
    "to_csv(\"train\", 60000)\n",
    "to_csv(\"t10k\", 10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90264dc",
   "metadata": {},
   "source": [
    "### 데이터를 저장하는 방식 : 12345678 데이터가 있다고 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6cfb57",
   "metadata": {},
   "source": [
    "#### 리틀엔디안 방식으로 저장 : 역순으로 저장\n",
    "\n",
    "- 0x78 -> 0x56 -> 0x32 -> 0x12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0327ae",
   "metadata": {},
   "source": [
    "#### 빅엔디안 방식으로 저장 : 순서대로 저장\n",
    "\n",
    "- 0x12 -> 0x34 -> 0x56 -> 0x78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e9a6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting number.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile number.py\n",
    "\n",
    "input = '5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 18 18 18 126 136 175 26 166 255 247 127 0 0 0 0 0 0 0 0 0 0 0 0 30 36 94 154 170 253 253 253 253 253 225 172 253 242 195 64 0 0 0 0 0 0 0 0 0 0 0 49 238 253 253 253 253 253 253 253 253 251 93 82 82 56 39 0 0 0 0 0 0 0 0 0 0 0 0 18 219 253 253 253 253 253 198 182 247 241 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 80 156 107 253 253 205 11 0 43 154 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 14 1 154 253 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 139 253 190 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 11 190 253 70 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 35 241 225 160 108 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 81 240 253 253 119 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 45 186 253 253 150 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 16 93 252 253 187 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 249 253 249 64 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 46 130 183 253 253 207 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 39 148 229 253 253 253 250 182 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 114 221 253 253 253 253 201 78 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 23 66 213 253 253 253 253 198 81 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 171 219 253 253 253 253 195 80 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 55 172 226 253 253 253 253 244 133 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 136 253 253 253 212 135 132 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n",
    "input = input.split(' ') # 공백기준으로 데이터 분리\n",
    "\n",
    "for i in range(len(input)):\n",
    "    print('{:3}'.format(input[i]), end=' ')\n",
    "    # print() 함수는 괄호를 닫을 때 Enter한다. end연산자는 한 줄로 만들때 사용\n",
    "    # end : 모든 데이터를 한 줄로 처리하라는 의미.\n",
    "    \n",
    "    if i % 28 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c827d2",
   "metadata": {},
   "source": [
    "# 데이터 분리 (학습용/테스트용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "633251fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header=None 이 값을 생략할 경우 첫번째 행이 헤더로 선언된다.\n",
    "\n",
    "train_csv = pd.read_csv('./mnist/train.csv', header=None)\n",
    "tk_csv = pd.read_csv('./mnist/t10k.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bd25693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f9da953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1461a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_csv[0].values\n",
    "test_label = tk_csv[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95cabddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_csv.iloc[:, 1:].values\n",
    "test_data = tk_csv.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77699fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_label))\n",
    "print(len(train_data))\n",
    "print(len(test_label))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5479932",
   "metadata": {},
   "source": [
    "loc[A4] : 하나만 가져올 때\n",
    "iloc[시작행:마지막행, 시작열:마지막열] : 여러 데이터 가져올 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa7d11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과 :  [7 2 1 ... 4 5 6]\n",
      "정확도 :  0.9792\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "predict = clf.predict(test_data)\n",
    "print(\"예측결과 : \" , predict)\n",
    "\n",
    "score = accuracy_score(test_label, predict)\n",
    "print(\"정확도 : \" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccedfe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.97      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.97      0.97      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(test_label, predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec5477",
   "metadata": {},
   "source": [
    "# 외국어 문장 판독하는 프로그램"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d5758",
   "metadata": {},
   "source": [
    "- lang\n",
    "    - train : 학습용으로 5개국어 샘플 노래 (20개)\n",
    "    - test : 테스트용으로 사용할 각 언어 샘플 2개씩\n",
    "    - sample : 영어노래 1개, 불어노래 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "873521d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/train/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b2541",
   "metadata": {},
   "source": [
    "#### 정답 추출\n",
    "\n",
    "- en-1.txt\n",
    "\n",
    "파일명에 - 기호를 중심으로 split 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f898a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl-20.txt tl\n",
      "en-5.txt en\n",
      "en-4.txt en\n",
      "en-1.txt en\n",
      "en-3.txt en\n",
      "fr-8.txt fr\n",
      "tl-18.txt tl\n",
      "fr-10.txt fr\n",
      "tl-19.txt tl\n",
      "fr-9.txt fr\n",
      "en-2.txt en\n",
      "id-15.txt id\n",
      "id-14.txt id\n",
      "id-13.txt id\n",
      "id-12.txt id\n",
      "id-11.txt id\n",
      "fr-7.txt fr\n",
      "tl-17.txt tl\n",
      "tl-16.txt tl\n",
      "fr-6.txt fr\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/train/*.txt')\n",
    "\n",
    "for file_name in files:\n",
    "    basename = os.path.basename(file_name)\n",
    "    lang = basename.split('-')[0]\n",
    "    print(basename, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2117f",
   "metadata": {},
   "source": [
    "### 파일들의 데이터를 읽어들인다. (알파벳 빈도수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/train/*.txt')\n",
    "\n",
    "for file_name in files:\n",
    "    basename = os.path.basename(file_name)\n",
    "    lang = basename.split('-')[0]\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    file = open(file_name, 'r', encoding='utf-8')\n",
    "    text = file.read()  # 파일에 들어있는 전체 데이터를 읽어들인다.\n",
    "    text = text.lower() # 가독성을 위해 소문자 처리\n",
    "    file.close()  # 파일 객체를 닫아준다.\n",
    "    \n",
    "    for c in text: # 알파벳 한글자씩 처리한다. 누적합계를 구하여 통계낸다.\n",
    "        print(c, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7b2a",
   "metadata": {},
   "source": [
    "#### 문자를 숫자로 변환하는 함수 = ord('문자')\n",
    "\n",
    "#### 숫자를 문자로 변환하는 함수 = chr(정수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7205d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54861"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('홍')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3f10df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'홍'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(54861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6dfab",
   "metadata": {},
   "source": [
    "#### 알파벳 출현 빈도수 구하기 (소문자 97 ~ 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d37449f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl [1469, 165, 142, 269, 466, 42, 240, 49, 548, 17, 107, 367, 173, 834, 491, 224, 13, 286, 472, 335, 202, 35, 42, 3, 246, 22]\n",
      "en [337, 93, 142, 181, 645, 93, 93, 260, 297, 15, 27, 181, 132, 284, 302, 86, 2, 331, 272, 436, 114, 49, 109, 14, 68, 3]\n",
      "en [383, 147, 159, 210, 642, 89, 125, 313, 346, 8, 69, 238, 114, 311, 465, 89, 2, 314, 389, 497, 129, 27, 104, 32, 93, 9]\n",
      "en [349, 59, 210, 212, 484, 72, 88, 201, 340, 8, 25, 247, 121, 356, 412, 76, 0, 357, 282, 370, 119, 45, 65, 3, 92, 2]\n",
      "en [259, 44, 165, 118, 434, 53, 91, 85, 342, 9, 6, 206, 81, 273, 277, 75, 6, 195, 318, 293, 105, 68, 43, 2, 65, 2]\n",
      "fr [585, 127, 321, 412, 1266, 105, 109, 116, 690, 35, 15, 500, 234, 596, 453, 189, 47, 661, 536, 492, 344, 122, 6, 41, 40, 16]\n",
      "tl [4100, 376, 45, 228, 532, 5, 1632, 201, 1256, 32, 557, 880, 628, 2414, 764, 559, 1, 480, 845, 1064, 621, 19, 255, 1, 352, 1]\n",
      "fr [1228, 163, 581, 831, 2347, 253, 167, 242, 1082, 36, 64, 1096, 418, 1126, 767, 406, 92, 1171, 1117, 1210, 834, 223, 11, 61, 57, 13]\n",
      "tl [2054, 264, 220, 252, 751, 57, 774, 220, 862, 22, 238, 491, 432, 1307, 648, 337, 5, 531, 682, 634, 322, 59, 95, 10, 270, 31]\n",
      "fr [405, 59, 181, 266, 735, 62, 103, 100, 461, 20, 12, 295, 127, 410, 306, 120, 24, 399, 371, 325, 225, 72, 2, 17, 27, 6]\n",
      "en [706, 167, 255, 326, 1149, 146, 262, 230, 632, 22, 82, 355, 203, 449, 577, 170, 46, 756, 601, 652, 257, 115, 117, 17, 90, 5]\n",
      "id [11092, 1581, 508, 2840, 5149, 315, 2102, 1283, 5464, 558, 2213, 2198, 2093, 6155, 2145, 1831, 11, 3504, 3350, 3093, 2665, 185, 384, 19, 796, 70]\n",
      "id [2522, 377, 68, 483, 1039, 118, 672, 224, 1451, 99, 611, 723, 647, 1326, 863, 442, 0, 746, 811, 742, 695, 33, 27, 3, 175, 8]\n",
      "id [4514, 594, 140, 986, 2129, 323, 1262, 475, 2218, 188, 1003, 904, 1067, 2528, 787, 765, 0, 1325, 1212, 1269, 1235, 40, 104, 6, 371, 6]\n",
      "id [1171, 196, 73, 313, 741, 88, 269, 147, 796, 42, 301, 295, 305, 672, 282, 276, 0, 370, 646, 403, 322, 64, 40, 11, 108, 5]\n",
      "id [253, 65, 29, 69, 194, 9, 120, 28, 210, 8, 50, 97, 59, 173, 75, 50, 0, 154, 139, 94, 85, 8, 13, 3, 19, 3]\n",
      "fr [1230, 221, 599, 761, 2550, 178, 179, 195, 1208, 51, 17, 1008, 711, 1290, 1048, 532, 112, 1301, 1325, 1111, 861, 215, 44, 84, 82, 2]\n",
      "tl [7231, 589, 164, 460, 758, 59, 2955, 555, 2799, 23, 1152, 1523, 1420, 4250, 1626, 948, 8, 762, 1779, 1475, 1074, 21, 299, 10, 926, 5]\n",
      "tl [6098, 672, 222, 360, 662, 96, 2633, 514, 2383, 35, 739, 1390, 826, 3478, 1223, 917, 24, 483, 1341, 1491, 752, 67, 339, 14, 550, 29]\n",
      "fr [2162, 414, 992, 1244, 4155, 327, 319, 350, 1998, 59, 54, 1804, 873, 1908, 1580, 809, 190, 2074, 2278, 1958, 1511, 295, 126, 108, 148, 13]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/train/*.txt')\n",
    "\n",
    "for file_name in files:\n",
    "    basename = os.path.basename(file_name)\n",
    "    lang = basename.split('-')[0]\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    file = open(file_name, 'r', encoding='utf-8')\n",
    "    text = file.read()  # 파일에 들어있는 전체 데이터를 읽어들인다.\n",
    "    text = text.lower() # 가독성을 위해 소문자 처리\n",
    "    file.close()  # 파일 객체를 닫아준다.\n",
    "    \n",
    "    code_a = ord('a') # 97\n",
    "    code_z = ord('z') # 122\n",
    "\n",
    "    count = [0] * 26\n",
    "\n",
    "    for c in text:\n",
    "        code_current = ord(c)\n",
    "\n",
    "        if code_a <= code_current <= code_z:\n",
    "            count[code_current - code_a] += 1\n",
    "        \n",
    "    print(lang, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76febaa6",
   "metadata": {},
   "source": [
    "- a와 z 의 격차가 크기 때문에 표준편차가 크다.\n",
    "- 따라서 정규화 작업을 해준다. \n",
    "\n",
    "en [337, 93, 142, 181, 645, 93, 93, 260, 297, 15, 27, 181, 132, 284, 302, 86, 2, 331, 272, 436, 114, 49, 109, 14, 68, 3]\n",
    "\n",
    "- 정규화 (Normalization) : 데이터를 0 ~ 1.0 사이의 값으로 대체한다.\n",
    "    - 모든 데이터를 합산한 후 고유값으로 나눈다.\n",
    "    \n",
    "- 머신러닝에서 필요한 값\n",
    "    - 수치값은 정규화 되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fb34f",
   "metadata": {},
   "source": [
    "### 필수로 알아야 할 함수\n",
    "\n",
    "- zip, map, filter, lambda, reduce, 컴퓨리핸션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a1fbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/train/*.txt')\n",
    "\n",
    "train_label = []\n",
    "train_data = []\n",
    "\n",
    "for file_name in files:\n",
    "    basename = os.path.basename(file_name)\n",
    "    lang = basename.split('-')[0]\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    file = open(file_name, 'r', encoding='utf-8')\n",
    "    text = file.read()  # 파일에 들어있는 전체 데이터를 읽어들인다.\n",
    "    text = text.lower() # 가독성을 위해 소문자 처리\n",
    "    file.close()  # 파일 객체를 닫아준다.\n",
    "    \n",
    "    code_a = ord('a') # 97\n",
    "    code_z = ord('z') # 122\n",
    "\n",
    "    count = [0] * 26\n",
    "\n",
    "    for c in text:\n",
    "        code_current = ord(c)\n",
    "\n",
    "        if code_a <= code_current <= code_z:\n",
    "            count[code_current - code_a] += 1\n",
    "        \n",
    "\n",
    "    # 정규화\n",
    "    total = sum(count)\n",
    "    count = list(map(lambda n: n/total, count))\n",
    "    \n",
    "    # 결과 저장\n",
    "    train_label.append(lang)\n",
    "    train_data.append(count)\n",
    "    \n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# glob 모듈은 파일이 있는 경로를 알려준다\n",
    "files = glob.glob('./lang/test/*.txt')\n",
    "\n",
    "test_label = []\n",
    "test_data = []\n",
    "\n",
    "for file_name in files:\n",
    "    basename = os.path.basename(file_name)\n",
    "    lang = basename.split('-')[0]\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    file = open(file_name, 'r', encoding='utf-8')\n",
    "    text = file.read()  # 파일에 들어있는 전체 데이터를 읽어들인다.\n",
    "    text = text.lower() # 가독성을 위해 소문자 처리\n",
    "    file.close()  # 파일 객체를 닫아준다.\n",
    "    \n",
    "    code_a = ord('a') # 97\n",
    "    code_z = ord('z') # 122\n",
    "\n",
    "    count = [0] * 26\n",
    "\n",
    "    for c in text:\n",
    "        code_current = ord(c)\n",
    "\n",
    "        if code_a <= code_current <= code_z:\n",
    "            count[code_current - code_a] += 1\n",
    "        \n",
    "\n",
    "    # 정규화\n",
    "    total = sum(count)\n",
    "    count = list(map(lambda n: n/total, count))\n",
    "    \n",
    "    # 결과 저장\n",
    "    test_label.append(lang)\n",
    "    test_data.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8b69bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과 :  ['tl' 'fr' 'en' 'en' 'en' 'id' 'fr' 'id' 'id' 'fr' 'tl']\n",
      "정확도 :  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       1.00      1.00      1.00         3\n",
      "          fr       1.00      1.00      1.00         3\n",
      "          id       1.00      1.00      1.00         3\n",
      "          tl       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "predict = clf.predict(test_data)\n",
    "print(\"예측결과 : \" , predict)\n",
    "\n",
    "score = accuracy_score(test_label, predict)\n",
    "print(\"정확도 : \" , score)\n",
    "\n",
    "report = metrics.classification_report(test_label, predict)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
